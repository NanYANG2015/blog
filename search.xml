<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于深度学习的语音评分</title>
      <link href="/blog/yu-yin/yu-yin-ping-ce/ping-fen/shen-du-xue-xi/"/>
      <url>/blog/yu-yin/yu-yin-ping-ce/ping-fen/shen-du-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="基于深度学习的语音评分">1. 基于深度学习的语音评分</h1><h2 id="2022-Self-Supervised">1.1. 2022 Self-Supervised</h2><ul><li>作者：AI Lab, Kakao Enterprise（韩国公司）</li></ul><h3 id="系统结构">1.1.1. 系统结构</h3><p><img src="https://note.youdao.com/yws/api/personal/file/BFDD37C3573F4F26B239C5302803D698?method=download&shareKey=cff7651e77f5b2b2f598af67f96793d9" alt="系统流程"><br>*GAP：global average pooling</p><ul><li>用L2数据+CTC fine-tune 自监督学习模型（wav2vec 2.0、HuBERT）；</li><li>取各transformer层的上下文表示的均值；</li><li>输入文本字符序列，采用BLSTM评分</li></ul><h3 id="评价">1.1.2. 评价</h3><ul><li>数据集：KESL（韩国英语二语学习者）、Speechocean762</li><li>基线：自研DNN-HMM AM。Agg: SpeechRater time-aggregated特征。Seq: 时间序列特征，eGeMAPS set[33]（包含MFCC、响度、音调、jitter、shimmer）的均值、方差，各特征均值方差归一化，采用OpenSmile提取。</li><li>自监督学习模型：采用Fairseq上的，finetune 150k步，batch size&#x3D;8</li><li>评分模型：embedding 64维，BLSTM 1层，128维</li></ul><p><img src="https://note.youdao.com/yws/api/personal/file/13BFFD96987142BA83ABE9698C5B1B24?method=download&shareKey=675676e74d6085d132469aee97282a55" alt="实验结果"></p><h3 id="其它">1.1.3. 其它</h3><ul><li>Kim E, Jeon J J, Seo H, et al. Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning[J]. arXiv preprint arXiv:2204.03863, 2022.</li></ul><h2 id="2022-Multi-Aspect-Multi-Granularity">1.2. 2022 Multi-Aspect Multi-Granularity</h2><ul><li>作者：MIT 人工智能实验室（CSAIL）、平安科技研究院（PAII Inc.）</li><li>发表信息：ICASSP 2022</li><li><font color="Red">代码：<a href="https://github.com/YuanGongND/gopt">https://github.com/YuanGongND/gopt</a></font> (Goodness Of Pronunciation feature-based Transformer)</li><li>创新点<ul><li>采用BERT风格非层级的标准Transformer 架构</li><li>联合训练音素、单词、句子级各维度分及总分</li></ul></li></ul><h3 id="系统结构-1">1.2.1. 系统结构</h3><p><img src="https://note.youdao.com/yws/api/personal/file/WEB915a9e1bc3fbd6be8224b3a8122dbfbd?method=download&shareKey=6c0e39f6c5b19fa1a9892f30ad805242" alt="系统结构"></p><ul><li>声学模型<ul><li>TDNN-F，训练集：960h Librispeech，用Kaldi Librispeech S5 recipe训练</li><li>PAII-A：自研AM，452h L1 + 1696h L2</li><li>PAII-B：995h L1 + 6591h L2</li></ul></li><li>输入<ul><li>GOP特征：84维（42个音素，log phone posterior、log posterior ratio），经过1层线性层降维至24维</li><li>正确发音phone embedding，24维。<ul><li>音素序列填充5个[cls] token，对应句子级各维度分、总分</li></ul></li><li>位置embedding，24维，可训练</li></ul></li><li>采用标准Transformer encoder结构，但减为3层，embedding 24维</li><li>评分：各个评分分别采用1层24*1的线性层，layer normalization。<font style="background: green">单词分：训练时反向传播至该单词的各个音素，推断时取其各个音素的输出的均值。</font></li></ul><h3 id="评价-1">1.2.2. 评价</h3><ul><li>数据集：speechocean762（类别不均衡，主要为高分），单词、句子评分缩放至0-2，与音素一致</li><li>评价指标：主要为PCC（Pearson相关系数）</li><li>基线：RF（随机森林）、SVR（支持向量回归）、[21]transfer learning、LSTM</li></ul><p><img src="https://note.youdao.com/yws/api/personal/file/WEBe86bc0edfdbde5c5f9c1462cd7bc2797?method=download&shareKey=a13ff3549e54e584ec7ebb674f8d68f3" alt="实验结果"></p><img src="https://note.youdao.com/yws/api/personal/file/WEBe04116ccf077c827de0f320a76641997?method=download&shareKey=7c437dbe136f2f972ca8c513e65879df" width="50%"><ul><li>实验结论<ul><li><font color="Red">GOPT除单词重音、句子完整度评分性能较差（可能与speechocean762训练集中句子完整度分布不均有关）外，其它任务可提供SOTA效果</font></li><li>采用PAII-A，单词、句子评分性能提升，但句子评分性能下降</li><li>联合训练音素、单词、句子评分模型，相对于分别训练，各模型性能都有提升。</li><li>正确发音phone embedding对提升模型性能有帮助</li><li>继续加宽或加深模型结构，性能无提升（训练集较小）</li><li>采用PAII-A、PAII-B，评分性能相当</li></ul></li></ul><h3 id="其它-1">1.2.3. 其它</h3><ul><li>Gong Y, Chen Z, Chu I H, et al. Transformer-Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment[C]&#x2F;&#x2F;ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022: 7262-7266.</li></ul><h2 id="2020-Multi-Granularity">1.3. 2020 Multi-Granularity</h2><ul><li>作者：腾讯智能平台产品部、北京语言大学</li><li>发表信息：Interspeech 2020</li><li>创新点：<ul><li>考虑音素、单词、句子评分间的层次关系和上下文，提出一种分层网络结构，联合评分</li><li>采用半监督训练，利用无标注数据训练音素检错</li></ul></li></ul><h3 id="系统结构-2">1.3.1. 系统结构</h3><p><img src="https://note.youdao.com/yws/api/personal/file/WEB15d8915a312dd0f51572a305759e4465?method=download&shareKey=06c0c6e07038fab09d0b18a838356915" alt="系统结构"></p><h3 id="音素检错">1.3.2. 音素检错</h3><ul><li>输入<ul><li>GOP：通过强制对齐计算</li><li>音素embedding</li><li>位置embedding：B、I、E、S分别表示单词开头、中间、末尾、单音素词。<font color="Red">音素发音因其在单词中的位置而异。</font></li><li>类别embedding：C、V分别表示辅音、元音。<font color="Red">单词中元音和辅音的重要性不同。</font></li></ul></li><li>半监督 - PUNU (positive unlabeled and negative unlabeled) learning<ul><li><p>正样本：native发音；负样本：GOP较低的L2学习者发音；unlabeled数据：剩下的L2发音。</p></li><li><p>损失函数如下：</p><p>$R_{\mathrm{PUNU}}^{\gamma}(g)&#x3D;(1-\gamma) R_{\mathrm{PU}}(g)+\gamma R_{\mathrm{NU}}(g)$<br>$R_{\mathrm{PU}}(g)&#x3D;\theta_{\mathrm{P}} E_{\mathrm{P}}[l(g(x), 1)]+E_{\mathrm{U}}[l(g(x),-1)]-\theta_{\mathrm{P}} E_{\mathrm{P}}[l(g(x),-1)]$<br>$R_{\mathrm{NU}}(g)&#x3D;\theta_{\mathrm{N}} E_{\mathrm{N}}[l(g(x),-1)]+E_{\mathrm{U}}[\mathrm{l}(g(x), 1)]-\theta_{\mathrm{N}} E_{\mathrm{N}}[l(g(x), 1)]$</p><p>其中, $g$ 为任意决策函数, $l$ 为 loss 函数, $\theta_P$、$\theta_N$ 为正负样本的先验概率, $E_U$、$E_P$、$E_N$ 分别表示未标记数据、正类、负类（边际）的损失期望。</p></li><li><p>模型结构：BLSTM</p></li></ul></li></ul><h3 id="单词评分">1.3.3. 单词评分</h3><p><font color="Red">单词中每个音素对最终单词得分的贡献不同，采用attention机制。</font></p><p>$U_{p}&#x3D;\tanh \left(w * O_{p}+b\right)$<br>$\alpha_{p}&#x3D;\frac{\exp \left(U_{p}^{T} U_{w}\right)}{\sum_{q \in w} \exp \left(U_{q}^{T} U_{w}\right)}$<br>$S_{w}&#x3D;\sum_{p \in w} \alpha_{p} O_{p}$</p><p><font style="background: green"> 其中, $O_p$ 为音素$p$的评分, $U_w$是随机初始化的向量, 可以作为单词上下文的记忆单元。</font></p><h3 id="句子评分">1.3.4. 句子评分</h3><ul><li><font color="Red">不同属性（如词性、音素个数）的单词对句子得分贡献不同。</font></li><li>输入：word层输出、词性、单词长度</li><li>模型结构：BLSTM+MLP，sigmoid回归。</li><li>multitask：$L_{total}&#x3D;(1-w)\times L_{sent}+ w\times L_{phoneme}$，$L_{sent}$其中为句子评分的均方误差损失，$L_{phoneme}$为PUNU损失。</li></ul><h3 id="评价-2">1.3.5. 评价</h3><ul><li>数据集<ul><li>Timit + 22998英语句子，1000中国说话人，16-20岁。句子评分、单词评分、音素检错标注量分别为8998、4000、10000句。句子平均单词数为13。标注音素量99568。</li><li>1-5分，3人评分取均值。3人评一致性：计算某一评分员的评分与剩余评分员的平均分之间的PCC，句子、词级分别为0.78、0.76。</li><li>检错3人投票，<font style="background: green"> 3人评一致性：随机挑选1000句，计算任意两标注员的Kappa系数，平均0.65，95%置信度区间(0.647, 0.653)，p-value小于0.1%，一致性较高。</font></li></ul></li><li>训练集：7998句non-native数据，有评分。5000句native数据，无评分。</li><li>测试集：4000句，标注了39808个音素、1000词、1000句。错误音素占比约14%。</li></ul><img src="https://note.youdao.com/yws/api/personal/file/WEB85b5a6de565f9c520658835b95786ba8?method=download&shareKey=8632f81f22963f5f07fd6cb3e9eef9d2" width="40%"><img src="https://note.youdao.com/yws/api/personal/file/WEB2d0fd1ee7ade8549ac8bcab6226f37e1?method=download&shareKey=2f0a145baa086763a420d45b143c03a9" width="30%"><img src="https://note.youdao.com/yws/api/personal/file/WEB4d0c8cbceb3537c0867f876ff2f2f3e7?method=download&shareKey=6e744f4ae6c8a59b0bb97a0674605191" width="30%"><ul><li>基线</li><li>实验结果<ul><li><p>句子评分效果</p><p>基线：2BLSTM+MLP，后一BLSTM的输入为音素BLSTM最后一个隐含单元的输出拼接、词性、单词长度</p><img src="https://note.youdao.com/yws/api/personal/file/WEBa5476cf9e1f6ac5f1ee3c5cdf4c56b69?method=download&shareKey=1c586ae1cc1ff426900c1b9e0fccfd67" width="30%"><p>*STL：single task learning</p><p>结论：单词层attention、multitask学习可提升评分性能</p></li><li><p>单词评分效果</p><p>基线：BLSTM+MLP：去掉上述句子评分BLSTM。SL：用3000个单词评分标注数据训练。</p><img src="https://note.youdao.com/yws/api/personal/file/WEB30a1747796429bff94888d09a7eb6ce1?method=download&shareKey=fd537dcca8a48cdd697826af548cdbd4" width="30%"><p>结论：对比前两行：attention机制有收益；最后一行：PCC较高，仅用句子、音素级标注信息，仍能学到单词分信息</p></li><li><p>音素检错效果</p><p>基线：SL：用59760个音素检错标注训练</p><img src="https://note.youdao.com/yws/api/personal/file/WEB8f8bcea9b4f939f430dd5b5985a7b779?method=download&shareKey=767fa915db6e5fe6e9c036fb5461cd0b" width="40%"><p>结论：半监督学习未召回略差于有监督学习，虚警相差较小</p></li></ul></li></ul><h3 id="其它-2">1.3.6. 其它</h3><ul><li>Lin B, Wang L, Feng X, et al. Automatic scoring at multi-granularity for L2 pronunciation[J]. Proc. Interspeech 2020, 2020: 3022-3026.</li></ul><h2 id="2021-Transfer-Learning">1.4. 2021 Transfer Learning</h2><ul><li>创新点：当前基于DNN-HMM的GOP计算存在许多局限性。相较于传统方案采用ASR AM计算GOP等评分特征，提出直接采用AM提取的深层特征进行评分。迁移学习：采用ASR预训练模型，用评分任务fine-tune。</li></ul><h3 id="系统结构-3">1.4.1. 系统结构</h3><ul><li><p>评分模型</p><ul><li>输入：ASR AM提取的深层特征、<font color="Red">对齐信息</font></li><li>基于强制对齐，对于各音素，对应帧的深层特征取均值，+ phone embedding</li><li>multi-head self-attention + 非线性变换，得到词级表示</li><li>self-attention + 非线性变换，得到句级表示</li><li>sigmoid，输出句级评分</li></ul><p><img src="https://note.youdao.com/yws/api/personal/file/WEBb8aabe4e549f1441e61dcc9a7716f7d3?method=download&shareKey=613e5a88949bb3da5e41d40b701034c4" alt="评分模型"></p></li><li><p>训练流程</p><ul><li>预训练11层TDNN-HMM ASR声学模型，深层特征256维，非线性变换降为32维</li><li>采用大量合成数据，用基于GOP的评分模型打分（low-quality），预训练评分模型</li><li>采用少量指定任务的专家标注数据fine-tune</li></ul></li></ul><h3 id="评价-3">1.4.2. 评价</h3><ul><li><p>数据集</p><ul><li>ASR：960h LibriSpeech + 1000h L2</li><li>合成数据：50000句</li><li>fine tune数据<ul><li>11000句（含1000句测试集），平均词数13，3位专家打分1-5</li><li>Speechocean762（50%用作测试集，分数缩放至0-1）</li></ul></li></ul></li><li><p>模型</p><ul><li><p>LayerNorm</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEBf2598f6a988b3abc7aa208f25151d084?method=download&shareKey=8e75af74d0c68b63984455913b513017" alt="参数量"></p></li></ul></li><li><p>实验结果</p><table><thead><tr><th>对比实验</th><th>实验结果</th><th>实验结论</th></tr></thead><tbody><tr><td>对比基于GOP的SOTA：<br>输入音素GOP、embedding，2层BLSTM+MLP；<br>输入音素GOP均值、各音素的平均位置（BIES）、句子音素总数，GBT</td><td><img src="https://note.youdao.com/yws/api/personal/file/WEB2584d9889200577d4e05c1c40b773378?method=download&shareKey=2ff0f42e16e7e3bd70ff3579ca55fa1d" alt="table2"></td><td></td></tr><tr><td>对比输入特征<br>STPs：考虑转移概率</td><td><img src="https://note.youdao.com/yws/api/personal/file/WEB41fd8d0028b57c6ac522716778d9bf76?method=download&shareKey=640db70f420eb058d02bf9acf6e4736c" alt="table3"></td><td><font style="background: green">采用音素GOP特征，当前模型效果差于2BLSTM+MLP？</font></td></tr><tr><td>冻结AM参数、3阶段训练</td><td></td><td>始终冻结AM参数+第2阶段预训练+finetune效果最好。评分模型参数量约为AM的0.2%，finetune高效</td></tr><tr><td>self-attention机制：对比替换为平均</td><td><img src="https://note.youdao.com/yws/api/personal/file/WEB448228dfdb5c057f5ff3834eb5266409?method=download&shareKey=a776ada79534cc24c131ec6d40c2d626" alt="table6"></td><td></td></tr></tbody></table></li></ul><h3 id="其它-3">1.4.3. 其它</h3><ul><li>Lin B, Wang L. Deep Feature Transfer Learning for Automatic Pronunciation Assessment[C]&#x2F;&#x2F;Interspeech. 2021: 4438-4442.</li></ul><h2 id="2019-ETS-monologue-and-dialogue">1.5. 2019 ETS monologue and dialogue</h2><ul><li>作者：ETS</li><li>发表信息：ICASSP 2019</li><li>创新点<ul><li>采用基于attention的BLSTM对自由表述的3个维度评分：内容（话题相关度、得体性）、 <del>组织（语篇结构和连贯性）、</del> 语用（词汇、语法）、delivery（发音、重音、流利度、语调）</li><li>采用BLSTM或MemN2N（端到端记忆网络）编码提示文本或多轮对话的历史信息</li></ul></li></ul><h3 id="系统结构-4">1.5.1. 系统结构</h3><p><img src="https://note.youdao.com/yws/api/personal/file/WEB05d8ea96857c948df270d54c2ea4bd7b?method=download&shareKey=13649c67fc1902c199e82d58e714a8e1" alt="系统结构"></p><ul><li><p>内容</p><ul><li><p>word embedding层：用Google’s Word2Vec初始化，模型训练时优化</p></li><li><p>采用BLSTM将提示文本的词序列编码为固定长度的向量$v^{p}$，与回答中各个词的词向量$e_{t}^{r}$拼接</p></li><li><p>采用MemN2N（端到端记忆网络）编码多轮对话的历史信息</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEBbee3fc2e061a11f9349e7cdf74c4a56d?method=download&shareKey=44b98cb337ce9340ba995bc7dbf86812" alt="MemN2N"></p><p>拼接$e_{t}^{r}$、$v^{p}$、$a^{p} \cdot v_{h}^{p}$、$a^{r} \cdot v_{h}^{r}$，其中，$v_{h}^{p}$、$v_{h}^{r}$分别表示历史提示、历史回答，$a^{p}$、$a^{r}$分别表示对应的attention向量</p></li></ul></li><li><p>语用特征：POS：词性one-hot向量；DEP：句法依存标签，如主语、宾语；Morph（形态）。采用spaCy提取，分别19、51、248维</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEB6be899029c0f7a47b674b1bf2a192990?method=download&shareKey=ca8d499efbb82aa9d542fba7f09661da" alt="示例"></p></li><li><p>发音：采用non-native ASR模型识别，native ASR模型<font color="Red">强制对齐</font>。8维特征：时长、音调、强度、静音或停顿时长、non-native ASR模型后验概率、native ASR模型后验概率、识别结果LM分、ASR置信度分，取各帧平均。</p></li><li><p>评分模型</p><ul><li>维度分：attention层输出向量的均值。多轮对话：对每个回答评维度分，整个对话的维度分取多轮对话的均值</li><li>总分：3个维度分拼接，经过1层全连接层</li></ul></li></ul><h3 id="评价-4">1.5.2. 评价</h3><ul><li><p>数据集</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEB5093f7bd21d0f1ad1ab6174a184a8dd4?method=download&shareKey=705b2902d86e06a96f4e9b67dbcfc520" alt="数据量"></p><ul><li>monolog：delivery、内容、语用，0-4分</li><li>对话：整个对话的总分，考虑熟练程度和任务完成情况</li></ul></li><li><p>声学模型</p><ul><li>识别模型：基于iVector的BLSTM，960h non-native数据。LM用提示文本自适应</li><li>强制对齐：960h LibriSpeech</li><li>提取语用、内容特征时过滤filler words、重复的partial words</li></ul></li><li><p>超参：BLSTM 128维。dropout&#x3D;0.5。100 epochs、batch size 64。MemN2N：记忆前10轮提示与回答，memory size 20</p></li><li><p>基线</p><ul><li>评分特征：SpeechRater，超过100个</li><li>回归模型：Logistic回归、AdaBoost、决策树、Gradient Boost、SVM、随机森林等。其中，随机森林效果最好。</li></ul></li><li><p>实验结果</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEBe2fe44d756ef9b96a97ae1d2f871de31?method=download&shareKey=0ea130ed2ffa18245bd99e5d4d685a31" alt="实验结果"></p><p>*预测的维度分与总分计算相关度，无人工标注</p></li><li><p>实验结论</p><ul><li>内容：结合提示信息，评分效果较好。采用MemN2N可进一步提高多轮对话内容评分与人工分的相关度。</li><li>发音采用音节级特征较好（音素级或音节级LM分：采用所属单词的LM分）</li><li>输入所有特征计算总分，效果更好，神经网络可以学习各维度特征间的关系。</li></ul></li></ul><h3 id="其它-4">1.5.3. 其它</h3><ul><li>Qian Y, Lange P, Evanini K, et al. Neural approaches to automated speech scoring of monologue and dialogue responses[C]&#x2F;&#x2F;ICASSP 2019-2019 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2019: 8112-8116.</li><li>展望：可解释性、诊断</li></ul><h2 id="2018-ETS-prompt-aware">1.6. 2018 ETS prompt-aware</h2><h3 id="其它-5">1.6.1. 其它</h3><ul><li>Qian Y, Ubale R, Mulholland M, et al. A prompt-aware neural network approach to content-based scoring of non-native spontaneous speech[C]&#x2F;&#x2F;2018 IEEE spoken language technology workshop (SLT). IEEE, 2018: 979-986.</li></ul><h2 id="2018-ETS-acoustics-transcription">1.7. 2018 ETS acoustics + transcription</h2><ul><li>作者：ETS</li><li>发表信息：ICASSP 2018</li><li>提示无关的神经网络评分模型（BD-LSTM + attention），输入识别文本word embedding、各单词的后验概率及声学特征，输出评分</li></ul><h3 id="系统结构-5">1.7.1. 系统结构</h3><p><img src="https://note.youdao.com/yws/api/personal/file/WEBd31cc498c578d02c7497165e2e58a513?method=download&shareKey=3bd314af1bfa5a11c60bfded4a5d2cd2" alt="系统结构"></p><ul><li>声学模型：DNN-HMM，训练集：819h non-native自发语音</li><li>评分模型输入<ul><li>lexical模型：识别文本word embedding序列。采用预训练的Glove模型，OOV采用全0向量，300维，训练评分模型时fine-tune</li><li>声学模型：每个词的声学模型后验概率、时长、pitch均值、intensity均值</li></ul></li><li>评分模型<ul><li>1D CNN<ul><li>参考[14]，采用3种尺寸的卷积核$\left(conv_{size}-1, conv_{size}, conv_{size}+1\right)$，用于覆盖不同的感受野。各$conv_{n}$个卷积核</li><li>input -&gt; dropout $dp_{CNN}1$ -&gt; 卷积层 -&gt; max pooling（沿时间轴） -&gt; dropout $dp_{CNN}2$</li></ul></li><li>BD-LSTM<ul><li>input -&gt; dropout $dp_{RNN}1$ -&gt; BD-LSTM -&gt; dropout $dp_{RNN}2$</li></ul></li><li>BD-LSTM + attention<ul><li>input -&gt; dropout -&gt; BD-LSTM -&gt; attention -&gt; dropout</li></ul></li><li>超参tuning：采用Hyperopt Python包实现的Tree Parzen Estimation (TPE)方法[23]。$conv_{size}&#x3D;4, conv_{n}&#x3D;100, dp_{CNN}1&#x3D;dp_{RNN}1&#x3D;0.25, dp_{CNN}2&#x3D;dp_{RNN}2&#x3D;0.5, LSTM_{dim}^{lex}&#x3D;128, LSTM_{dim}^{ac}&#x3D;32$</li></ul></li></ul><h3 id="评价-5">1.7.2. 评价</h3><ul><li><p>数据集：训练集 2930，开发集 731，测试集 1827。4分制。</p></li><li><p>传统模型（基线）</p><ul><li><p>随机森林、GBT（Gradient Boosting Tree）、SVR（Support Vector Regression）。其中，GBT模型人-机评分相关度最高。</p></li><li><p>评分特征</p><p><img src="https://note.youdao.com/yws/api/personal/file/WEB2b3d68c3d17278fcc388c60f44fbca7b?method=download&shareKey=93dba1172f8282c23aea663f0988cfed" alt="评分特征"></p><table><thead><tr><th>类别</th><th>特征示例</th></tr></thead><tbody><tr><td>流利度</td><td>单词数&#x2F;秒、单词数&#x2F;段、静音段个数、静音段平均时长、长停顿（&gt;0.5s）频率、有声停顿（uh、um）个数</td></tr><tr><td>韵律、语调、重音</td><td>韵律事件（prominences and boundary tones）的占比、之间的平均距离、距离的平均差，元音、辅音、音节时长的占比、标准差、Pairwise Variability Index</td></tr><tr><td>发音</td><td>native AM 强制对齐计算likelihood、ASR词级置信度均值、在native语料上统计各元音的时长均值，计算测试数据元音时长与参考值的差值的均值</td></tr><tr><td>语法</td><td></td></tr><tr><td>用词</td><td>多样性、复杂度</td></tr></tbody></table></li></ul></li><li><p>实验结果</p><img src="https://note.youdao.com/yws/api/personal/file/WEB80c4a6aa4b8e87255eb450053d7e42d9?method=download&shareKey=19bfa2868abd6d958f9a91870d239584" width="50%"><p>相较于传统评分模型采用n-gram提取评分特征，word embedding可提供更丰富的信息</p></li><li><p>展望：可解释性、更多声学特征、其它attention机制</p></li></ul><h3 id="其它-6">1.7.3. 其它</h3><ul><li><p>Chen L, Tao J, Ghaffarzadegan S, et al. End-to-end neural network based automated speech scoring[C]&#x2F;&#x2F;2018 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2018: 6234-6238.</p></li><li><p>Yu Z, Ramanarayanan V, Suendermann-Oeft D, et al. Using bidirectional LSTM recurrent neural networks to learn high-level abstractions of sequential features for automated scoring of non-native spontaneous speech[C]&#x2F;&#x2F;2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015: 338-345.</p></li><li><p>Taghipour K, Ng H T. A neural approach to automated essay scoring[C]&#x2F;&#x2F;Proceedings of the 2016 conference on empirical methods in natural language processing. 2016: 1882-1891.</p><p>CNN（提取局部上下文信息）+ RNN（提取长时信息）+ mean over time回归（利用全文信息）</p></li></ul><h2 id="2020-spectrograms-transcriptions">1.8. 2020 spectrograms + transcriptions</h2><h3 id="其它-7">1.8.1. 其它</h3><ul><li>Grover M S, Kumar Y, Sarin S, et al. Multi-modal automated speech scoring using attention fusion[J]. arXiv preprint arXiv:2005.08182, 2020.</li></ul><h2 id="2022-Deep-Learning-for-Automatic-Assessment-and-Feedback-of-Spoken-English">1.9. 2022 Deep Learning for Automatic Assessment and Feedback of Spoken English</h2><ul><li>发表信息：剑桥大学博士论文</li></ul><h3 id="其它-8">1.9.1. 其它</h3><p>Kyriakopoulos K. Deep Learning for Automatic Assessment and Feedback of Spoken English[D]. University of Cambridge, 2022.</p><h2 id="2022-Chinese-English-interpretation口语翻译">1.10. 2022 Chinese-English interpretation口语翻译</h2><ul><li>作者：广东外语外贸大学</li></ul><h3 id="系统结构-6">1.10.1. 系统结构</h3><ul><li><p>流畅度分：语速</p></li><li><p><font color="Red">关键字、内容、语法：采用Bert预训练模型、BiLSTM、attention机制</font></p><img src="https://note.youdao.com/yws/api/personal/file/WEB2a27b65f57024957f23441b7cf64123f?method=download&shareKey=d00680ca591a47f6ec40226486adbc31" width="50%"></li><li><p>采用随机森林回归器融合4个维度分计算总分</p></li></ul><h2 id="2022-Word-Scoring">1.11. 2022 Word Scoring</h2><ul><li>作者：字节跳动</li><li>创新点：<ul><li>数据增强：给定词典中的音素序列，从训练数据相应的音素级特征中随机抽样来伪造单词样本，单词分取音素GOP均值</li><li>引入MFCC、deep feature</li></ul></li></ul><p><img src="https://note.youdao.com/yws/api/personal/file/WEBe00917195f9a8da3492d09eff12bc9f6?method=download&shareKey=55db844dfc0db67bba44ab887f6bea6b" alt="数据增强"></p><h3 id="其它-9">1.11.1. 其它</h3><p>Fu K, Gao S, Wang K, et al. Improving Non-native Word-level Pronunciation Scoring with Phone-level Mixup Data Augmentation and Multi-source Information[J]. arXiv preprint arXiv:2203.01826, 2022.</p><h2 id="【弃】2020-Automated-chinese-language-proficiency-scoring-by-utilizing-siamese-convolutional-neural-network-and-fusion-based-approach">1.12. 【弃】2020 Automated chinese language proficiency scoring by utilizing siamese convolutional neural network and fusion based approach</h2><ul><li>论文质量较差，弃</li><li>自制数据集</li></ul><h3 id="系统结构-7">1.12.1. 系统结构</h3><ul><li>native speakers’ key points、测试者语音，提取100*300维向量 -&gt; 分别送入权重共享的卷积层 -&gt; pooling层 -&gt; 计算cosine相似度 -&gt; 线性层输出分数</li><li>人工设计的特征：详见SpeechRater v5.0。提取tf-idf特征，计算测试语音、同一单词人工分4分的训练语音的cosine 相似度</li></ul><h3 id="其它-10">1.12.2. 其它</h3><ul><li>Kwong A, Muzamal J H, Zhang P Y, et al. Automated chinese language proficiency scoring by utilizing siamese convolutional neural network and fusion based approach[C]&#x2F;&#x2F;2020 International Conference on Engineering and Emerging Technologies (ICEET). IEEE, 2020: 1-6.</li><li>语音评测系统质量控制[37, 39-42]</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音评测 </category>
          
          <category> 评分 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>WeNet论文</title>
      <link href="/blog/yu-yin/gong-ju-bao/wenet/lun-wen/"/>
      <url>/blog/yu-yin/gong-ju-bao/wenet/lun-wen/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 工具包 </category>
          
          <category> WeNet </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cleanup_segmentation</title>
      <link href="/blog/yu-yin/gong-ju-bao/kaldi/cleanup-segmentation.mm/"/>
      <url>/blog/yu-yin/gong-ju-bao/kaldi/cleanup-segmentation.mm/</url>
      
        <content type="html"><![CDATA[<div class="markmap-container" style="height:800px">  <svg data="{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:1,&quot;p&quot;:{&quot;lines&quot;:[0,1]},&quot;v&quot;:&quot;run_cleanup_segmentation.sh&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[2,3]},&quot;v&quot;:&quot;clean_and_segment_data.sh &lt;br/&gt; 采用转写文本构建语言模型，选取和转写文本编辑距离最小的解码路径；&lt;br/&gt;若识别为连续的重复，non-scored words间的错误，与sil、fix、OOV相邻的删除错误，修正转写文本；&lt;br/&gt; 挑选识别正确的片段，并加一系列限定条件 &lt;br/&gt; &lt;font style=background:green&gt; 输入&amp;lt;srcdir&amp;gt;：SAT GMM模型目录，或fMLLR对齐结果&lt;/font&gt; &lt;br/&gt; clean_and_segment_data_nnet3.sh 区别：功能一致，用NNET3模型解码&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[4,5]},&quot;v&quot;:&quot;make_biased_lm_graphs.sh&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[5,6]},&quot;v&quot;:&quot;取转写文本中top_n_words（默认值100）个高频词，unigram概率=频次/高频词总频次&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[6,7]},&quot;v&quot;:&quot;make_biased_lms.py&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[7,8]},&quot;v&quot;:&quot;根据min-words-per-graph（默认值100）将音频文本分组&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[8,9]},&quot;v&quot;:&quot;make_one_biased_lm.py&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:9,&quot;p&quot;:{&quot;lines&quot;:[9,10]},&quot;v&quot;:&quot;统计第n阶的count&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:9,&quot;p&quot;:{&quot;lines&quot;:[10,11]},&quot;v&quot;:&quot;CompletelyDiscountLowCountStates&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:11,&quot;p&quot;:{&quot;lines&quot;:[11,12]},&quot;v&quot;:&quot;GetHistToTotalCount：统计各历史/前缀（长度&amp;gt;=2）出现的频次&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:11,&quot;p&quot;:{&quot;lines&quot;:[12,13]},&quot;v&quot;:&quot;对第n至3阶，若历史/前缀出现的频次&amp;lt;min_count（默认值10），删除该项，并回退&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:9,&quot;p&quot;:{&quot;lines&quot;:[13,14]},&quot;v&quot;:&quot;&lt;font style=background:green&gt;ApplyBackoff：对第2至n阶，各项频次折扣discounting-constant（默认值0.3），累加给backoff_symbol，相应的低1阶的频次+1&lt;/font&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:9,&quot;p&quot;:{&quot;lines&quot;:[14,15]},&quot;v&quot;:&quot;&lt;font style=background:green&gt;AddTopWords：添加高频词unigram，频次为unigram总频次*概率&lt;/font&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:9,&quot;p&quot;:{&quot;lines&quot;:[15,16]},&quot;v&quot;:&quot;PrintAsFst：ngram概率=折扣后的ngram概率+折扣的概率*低1阶的概率，打印FST&quot;}]}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[16,17]},&quot;v&quot;:&quot;compile-train-graphs-fsts：生成group HCLG&quot;}]},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[18,19]},&quot;v&quot;:&quot;decode_segmentation.sh：gmm-latgen-faster&quot;},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[20,21]},&quot;v&quot;:&quot;analyze_lats.sh&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[21,22]},&quot;v&quot;:&quot;lattice-depth-per-frame：lattice中经过各帧的弧数&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[22,23]},&quot;v&quot;:&quot;lattice-best-path：获取 1best 识别和对齐&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[23,24]},&quot;v&quot;:&quot;ali-to-phones --write-lengths=true&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[24,25]},&quot;v&quot;:&quot;analyze_phone_length_stats.py 统计各音素时长分布&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[25,26]},&quot;v&quot;:&quot;ali-to-phones --per-frame=true&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[26,27]},&quot;v&quot;:&quot;analyze_lattice_depth_stats.py 统计各音素lattice depth分布&quot;}]},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[28,29]},&quot;v&quot;:&quot;lattice_oracle_align.sh&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[29,30]},&quot;v&quot;:&quot;lattice-oracle：获取和转写文本编辑距离最小的解码路径&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[30,31]},&quot;v&quot;:&quot;get_ctm&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[31,32]},&quot;v&quot;:&quot;&lt;font style=background:green&gt;lattice-align-words-lexicon 对齐词边界&lt;/font&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[32,33]},&quot;v&quot;:&quot;&lt;font style=background:green&gt;lattice-1best 获取最优路径（消歧符可能导致上述lattice有多条路径）&lt;/font&gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[33,34]},&quot;v&quot;:&quot;nbest-to-ctm 打印utt_id, channel, start, dur, word_id&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[34,35]},&quot;v&quot;:&quot;align-text&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[35,36]},&quot;v&quot;:&quot;wer_per_utt_details.pl：打印utt-id、编辑距离、转写词数、解码结果、转写&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[36,37]},&quot;v&quot;:&quot;wer_per_spk_details.pl&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[37,38]},&quot;v&quot;:&quot;wer_ops_details.pl：打印各个词识别为正确、插入、删除、替换的频次&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[38,39]},&quot;v&quot;:&quot;get_ctm_edits.py：打印utt_id, channel, start, dur, 识别的单词, 置信度(始终为1），转写的单词, 编辑类型 &lt;br/&gt;（其中，sil表示无对应的转写单词且识别为&amp;lt;eps&amp;gt; sil；若转写单词不在词典中且识别为&amp;lt;unk&amp;gt;则编辑类型为cor）&quot;}]},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[40,41]},&quot;v&quot;:&quot;modify_ctm_edits.py：若识别为non-scored words（!sil, &amp;lt;eps&amp;gt;, &amp;lt;spoken_noise&amp;gt;, &amp;lt;unk&amp;gt;）间的替换、插入、删除，&lt;br/&gt;或者识别为连续的重复（如转写文本为a，识别为a a；或转写文本为a b，识别为a b a b），&lt;br/&gt;将转写文本中的词替换为识别文本中的，前者编辑类型改为fix，后者编辑类型改为cor&quot;},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[42,43]},&quot;v&quot;:&quot;taint_ctm_edits.py：识别错误前后连续相邻的sil、fix、OOV识别为&amp;lt;unk&amp;gt; 标记为tainted；若该识别错误为删除且前/后有tainted，删除该行&quot;},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[44,45]},&quot;v&quot;:&quot;segment_ctm_edits.py&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[45,46]},&quot;v&quot;:&quot;默认参数&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[46,47]},&quot;v&quot;:&quot;片段最短时长0.5s、新片段最短时长1s&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[47,48]},&quot;v&quot;:&quot;tainted词最大时长0.05s&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[48,49]},&quot;v&quot;:&quot;片段首尾静音最大时长0.5s（若导致不满足片段最短时长或新片段最短时长，放宽该条件）&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[49,50]},&quot;v&quot;:&quot;片段首尾non-scored word最大时长0.5s（若导致不满足片段最短时长，放宽该条件）&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[50,51]},&quot;v&quot;:&quot;片段内单个静音段最大时长2s、片段内单个non-scored word&lt;font style=background:green&gt;（除OOV，实现未考虑）&lt;/font&gt;最大时长2s&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[51,52]},&quot;v&quot;:&quot;如果片段首尾靠近识别错误，填充0.05s &amp;lt;unk&amp;gt;&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[52,53]},&quot;v&quot;:&quot;tainted词+填充的unk占片段时长的最大比例0.1&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[53,54]},&quot;v&quot;:&quot;根据上一条规则分段时，分割点静音段或non-scored word的最短时长0.1s&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[54,55]},&quot;v&quot;:&quot;合并重叠或相邻的片段时，若片段间删除的转写词数&amp;lt;=1，保留&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[55,56]},&quot;v&quot;:&quot;GetSegmentsForUtterance&quot;,&quot;c&quot;:[{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[56,57]},&quot;v&quot;:&quot;ComputeSegmentCores：挑选仅含cor、fix、sil的片段，至少有一个词识别为cor且不为OOV，不包含tainted&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[57,58]},&quot;v&quot;:&quot;PossiblyAddTaintedLines：若边界识别为cor并且单词非non-scored word，前后相邻的1个词为tainted，扩充该词&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[58,59]},&quot;v&quot;:&quot;PossiblySplitSegment：根据片段内静音最大时长、片段内non-scored word最大时长分段，将识别为sil或转写文本为non-scored word的词均分&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[59,60]},&quot;v&quot;:&quot;PossiblyTruncateBoundaries：根据片段首尾静音最大时长、片段首尾non-scored word最大时长 截断片段首尾sil或non-scored word&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[60,61]},&quot;v&quot;:&quot;RelaxBoundaryTruncation：片段首尾非tainted截断：若满足片段时长&amp;gt;=片段最短时长、新片段最短时长，不撤销；若全撤销后仍不满足，全撤销；否则放宽截断比例至正好满足条件。&lt;br/&gt;令b=1-a，则length_with_truncation + (length_with_relaxed_boundaries - length_with_truncation) * b = length_cutoff &lt;br/&gt; start_keep_proportion = orig_start_keep_proportion + (1-orig_start_keep_proportion) * b&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[61,62]},&quot;v&quot;:&quot;PossiblyAddUnkPadding：若片段首尾识别为cor并且非non-scored word，填充unk_padding：不超过音频起止时刻；若填充时长&amp;lt; 0.5*unk_padding，不填充&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[62,63]},&quot;v&quot;:&quot;删除不满足新片段最短时长、片段最短时长的片段&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[63,64]},&quot;v&quot;:&quot;PossiblyTruncateStartForJunkProportion：若片段起始 (unk_padding+tainted词时长)/(时长&amp;gt;min_split_point_duration，第一个识别为sil或识别为cor的non_scored_word前的时长) &amp;gt;= max_junk_proportion，删除该词前的片段&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[64,65]},&quot;v&quot;:&quot;PossiblyTruncateEndForJunkProportion：同上，处理片段末尾&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[65,66]},&quot;v&quot;:&quot;ContainsAtLeastOneScoredNonOovWord：片段包含至少一个识别为cor、非OOV的scored_word，否则删除&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[66,67]},&quot;v&quot;:&quot;若片段首尾(unk_padding+tainted词)时长占比&amp;gt;max_junk_proportion，删除该片段&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:7,&quot;p&quot;:{&quot;lines&quot;:[67,68]},&quot;v&quot;:&quot;合并重叠或相连的片段：若重叠片段包含的识别为del的词数&amp;gt;合并时保留的最大删除词数，则text不包含这些词&quot;}]},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[68,69]},&quot;v&quot;:&quot;AccWordStatsForUtterance：统计转写文本中各个词的词频、不被包含在分段中的比例&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[69,70]},&quot;v&quot;:&quot;WriteSegmentsForUtterance：写分段转写文本text和segment文件&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[70,71]},&quot;v&quot;:&quot;PrintDebugInfoForUtterance：写ctm文件&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[71,72]},&quot;v&quot;:&quot;PrintSegmentStats：打印音频总数，被完全丢弃的音频数，总时长，每一步处理后segment数目、相对于原始数据的时长比例&quot;},{&quot;t&quot;:&quot;list_item&quot;,&quot;d&quot;:5,&quot;p&quot;:{&quot;lines&quot;:[72,73]},&quot;v&quot;:&quot;PrintWordStats&quot;}]},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[74,75]},&quot;v&quot;:&quot;创建数据文件夹：统计padding=训练集（音频时长-特征时长）最高频的值，segment结束时刻+=padding &lt;br/&gt; 主要处理feats.scp、vad.scp，cmvn.scp需要重新生成&quot;},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:3,&quot;p&quot;:{&quot;lines&quot;:[76,77]},&quot;v&quot;:&quot;重新计算CMVN&quot;}]},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[78,79]},&quot;v&quot;:&quot;对齐清洗后数据&quot;},{&quot;t&quot;:&quot;heading&quot;,&quot;d&quot;:2,&quot;p&quot;:{&quot;lines&quot;:[80,81]},&quot;v&quot;:&quot;重训GMM模型&quot;}]}"/></div><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 工具包 </category>
          
          <category> Kaldi </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>评分标准</title>
      <link href="/blog/yu-yin/yu-yin-ping-ce/ping-fen-biao-zhun/"/>
      <url>/blog/yu-yin/yu-yin-ping-ce/ping-fen-biao-zhun/</url>
      
        <content type="html"><![CDATA[<h1 id="评分标准">1. 评分标准</h1><h2 id="考纲">1.1. 考纲</h2><ul><li><a href="http://www.neea.edu.cn/res/Home/1901/d15ec0514666ac280810099f9595b557.pdf">普通高等学校招生全国统一考试大纲-2019</a><ul><li>语音项目<ul><li>基本读音：辅音连缀、成音节、单词重音</li><li>连读、失去爆破、弱读、同化</li><li>意群与停顿、语调、句子重音、节奏</li></ul></li></ul></li><li>英语口语等级考试三级考试大纲-2018（湖北省教育考试院）<a href="http://www.hbea.edu.cn/html/2018-11/12162.html">^湖北SETS</a><ul><li>短文朗读：语音语调（权重0.6）、流利程度（权重0.4）</li><li>情景提问：语音语调（权重0.2）、语法词汇（权重0.45）、流利程度与交际能力（权重0.35）</li><li>情景应答：语音语调（权重0.2）、语法词汇（权重0.45）、流利程度与交际能力（权重0.35）</li><li>连续表达：语音语调（权重0.2）、语法词汇（权重0.3）、流利程度（0.2）、交际能力（权重0.3）</li><li>分档：4档，百分制 &gt;&#x3D;85、&gt;&#x3D;75、&gt;&#x3D;60、&lt;60</li></ul></li><li>广东高考-2011：模仿朗读、情景问答、故事复述<a href="https://baike.baidu.com/item/%E5%B9%BF%E4%B8%9C%E9%AB%98%E8%80%83%E8%8B%B1%E8%AF%AD%E5%90%AC%E8%AF%B4%E8%80%83%E8%AF%95/2678957">^广东高考</a></li><li>广西高考-2021 <a href="%5B%E5%B9%BF%E8%A5%BF%E9%AB%98%E8%80%83-2021%EF%BC%88%E6%8B%9B%E7%94%9F%E8%80%83%E8%AF%95%E9%99%A2%EF%BC%89%5D(https://www.gxeea.cn/gallary/upload_images/1173_26561_1606206201913.pdf)">^广西高考</a><ul><li>模仿朗读：语音语调（权重0.5）、流利度（权重0.3）、完整度（权重0.2）</li><li>口头表达：内容（权重0.5）、语法（0.27）、语音语调+流利度（0.23）</li></ul></li><li>2019年江苏省初中英语听力口语自动化考试纲要：朗读短文（4档）、情景问答（2档）、话题简述（4档）<a href="https://jys.jsies.cn/htmledit/uploadfile/20190111153949047.pdf">^江苏中考</a></li><li>宁波市2022年初中学业水平考试英语听力口语自动化考试说明：朗读短文（4档）、情景问答（3档）、话题简述（4档）<a href="http://nbeea.nbedu.net.cn/ckfile/files/%E5%AE%81%E6%B3%A2%E5%B8%822022%E5%B9%B4%E5%88%9D%E4%B8%AD%E5%AD%A6%E4%B8%9A%E6%B0%B4%E5%B9%B3%E8%80%83%E8%AF%95%E8%8B%B1%E8%AF%AD%E5%90%AC%E5%8A%9B%E5%8F%A3%E8%AF%AD%E8%87%AA%E5%8A%A8%E5%8C%96%E8%80%83%E8%AF%95%E8%AF%B4%E6%98%8E.pdf">^宁波中考</a></li><li><a href="http://jyj.panjin.gov.cn/2019_09/24_00/content-65069.html">盘锦中考-2019</a>：朗读（4档）、情景问答（3档）</li><li><a href="http://edu.wenzhou.gov.cn/art/2022/3/3/art_1341152_59021518.html">温州中考-2022</a>：篇章朗读、情景问答、说话 （无评分标准介绍）</li></ul><h2 id="维度分考察点">1.2. 维度分考察点</h2><table><thead><tr><th>维度分</th><th>考察点</th><th>备注</th><th>分档描述</th></tr></thead><tbody><tr><td>发音准确度</td><td>语音、声调&#x2F;单词重音</td><td>与完整度无关，自由表述题中与正确答案无关[^先声]</td><td>5档：<br>语音、语调清晰、准确；<br>有错误，但不影响理解；<br>有错误，且有时影响理解；<br>有多处错误，且影响理解；<br>表现出较严重发音困难，且严重影响理解[^广西高考]</td></tr><tr><td>流畅度</td><td>语速、停顿次数、重复[^1]</td><td>与朗读的内容无关[^先声] <font style="background: green">（回读）</font></td><td>5档：<br>朗读自然流利，语速适中，有节奏感[^宁波中考]无语流中断，停顿和反复现象很少[^湖北SETS]；<br>基本流畅；<br>部分话语不够流畅；<br> 话语大部分不流畅; <br> 不流畅[^广西高考]</td></tr><tr><td>标准度&#x2F;韵律</td><td>无中式口音，能灵活地运用连读、重读、失去爆破等发音技巧，节奏良好，感情充沛[^1]<br>意群停顿、升降调、句子重音[^先声]</td><td></td><td></td></tr><tr><td>完整度</td><td>朗读题：已读内容占提示文本的比例<br>自由表述题：要点覆盖率</td><td></td><td>5档：<br>内容丰富，完整、连贯；<br>内容基本完整、偶尔不够连贯；<br>有部分陈述不够完整，有时不连贯；<br>大部分陈述不完整，或不连贯；严重缺乏完整性和连贯性[^广西高考]</td></tr><tr><td>语法</td><td>人称、单复数、时态、语态、动词的及物性；<br>词汇、短语、语法结构使用[^广西高考]</td><td></td><td>5档：<br>能用合适的词汇、短语、语法结构组织话语；<br>个别地方出现错误；<br>少量错误；<br>大部分不正确；<br>不能正确使用[^广西高考]</td></tr></tbody></table><h2 id="音标朗读">1.3. 音标朗读</h2><h2 id="单词朗读">1.4. 单词朗读</h2><h2 id="短文朗读">1.5. 短文朗读</h2><h3 id="总分与维度分">1.5.1. 总分与维度分</h3><blockquote><p>成人句子：total_score &#x3D; (0.6*accuracy_score + fluency_score*0.3 + standard_score*0.1)* integrity_score&#x2F;100</p><p>成人篇章：total_score &#x3D; (0.5*accuracy_score + fluency_score*0.3 +standard_score*0.2)* integrity_score&#x2F;100 <a href="https://www.xfyun.cn/doc/Ise/IseAPI.html">^1</a></p></blockquote><h2 id="单项选择">1.6. 单项选择</h2><p>用户只能按事先设定的固定答案作答；只有读正确答案并且发音正确、完整，才有得分；用户回答多个选项，以后面的回答为准。<a href="https://open.singsound.com/doc/engine?type=engine-en-en.sent.score">^先声</a></p><h2 id="情景问答">1.7. 情景问答</h2><h3 id="题型说明">1.7.1. 题型说明</h3><p>先描述一段场景，然后从描述的场景中提出一个问题，让回答者根据听到的场景回答问题<a href="https://open.singsound.com/doc/engine?type=engine-en-en.sent.score">^先声</a></p><h3 id="示例">1.7.2. 示例</h3><p><a href="https://www.chivox.com/opendoc/#/ChineseDoc/coreEn">^先声</a></p><pre class="line-numbers language-none"><code class="language-none">&quot;para&quot;（描述情景的文本）: &quot;It&#39;s unbelievable. He looks stupid, but in fact, he is such a great and humorous actor. What&#39;s going on? You know what? Mr. Bean graduate from Oxford University. Exactly, I am also very crazy about Mr. Bean. He is really a funny guy and he does have a great sense of humor. In my eyes, he is a genius. I really admire him. I couldn&#39;t agree more, and it&#39;s his giftedness and hard works that make him succeed. After seeing his interesting films, I feel cheerful and excited, he brings happiness to us. Yes, I hope we can bring laughter to people too, just like Mr. Bean. I can&#39;t wait to see more his films after class. But first thing first, let&#39;s get our homework done.&quot;,&quot;quest_ans&quot;（提问问题的文本）: &quot;What makes Mr. Bean so successful?&quot;,&quot;lm&quot;（可能的正确回答；每个text表示一种正确的回答）: [    &#123;&quot;text&quot;: &quot;It&#39;s his giftedness and hard works that make him succeed.&quot;&#125;,    &#123;&quot;text&quot;: &quot;his talents and hard works.&quot;&#125;,    &#123;&quot;text&quot;: &quot;is talent and hard work.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His giftedness and hard works.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His giftedness and hard works makes Mr. Bean so successful.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His talent and hard work makes him successful.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His body language is so funny, he makes people laugh, feel happy and relaxed.&quot;&#125;,    &#123;&quot;text&quot;: &quot;Hard work and giftedness.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His giftedness and hard work.&quot;&#125;,    &#123;&quot;text&quot;: &quot;his talents and he is very hard working.&quot;&#125;,    &#123;&quot;text&quot;: &quot;His gift and hard works.&quot;&#125;],&quot;key&quot;（关键点可能的表述方式；关键点对打分的影响很大）:     [[&quot;giftedness&quot;, &quot;gift&quot;, &quot;talent&quot;], &quot;hard work&quot;],&quot;unkey&quot;（错误答案，用户发音命中其中任一错误答案，对得分影响很大，得分会较低）:[&quot;no&quot;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="评分标准-1">1.7.3. 评分标准</h3><h4 id="广东高考">1.7.3.1. 广东高考</h4><p><a href="https://baike.baidu.com/item/%E5%B9%BF%E4%B8%9C%E9%AB%98%E8%80%83%E8%8B%B1%E8%AF%AD%E5%90%AC%E8%AF%B4%E8%80%83%E8%AF%95/2678957">^广东高考</a></p><table><thead><tr><th></th><th>权重</th><th>分档描述</th></tr></thead><tbody><tr><td>信息</td><td>75%</td><td>1.5分：按照要求传递了信息；<br>1分：基本按照要求传递信息（漏了一、两点次要信息、或添加了无关信息）；<br>0分：不能按照要求传递信息</td></tr><tr><td>语言</td><td>25%</td><td>0.5分：不影响理解所表达的信息；<br>0分：导致不能理解所表达的信息</td></tr></tbody></table><h4 id="宁波中考">1.7.3.2. 宁波中考</h4><p><a href="http://nbeea.nbedu.net.cn/ckfile/files/%E5%AE%81%E6%B3%A2%E5%B8%822022%E5%B9%B4%E5%88%9D%E4%B8%AD%E5%AD%A6%E4%B8%9A%E6%B0%B4%E5%B9%B3%E8%80%83%E8%AF%95%E8%8B%B1%E8%AF%AD%E5%90%AC%E5%8A%9B%E5%8F%A3%E8%AF%AD%E8%87%AA%E5%8A%A8%E5%8C%96%E8%80%83%E8%AF%95%E8%AF%B4%E6%98%8E.pdf">^宁波中考</a></p><table><thead><tr><th>分值</th><th>评分标准</th></tr></thead><tbody><tr><td>1</td><td>意思明白，表达清楚，语音、语调正确，词语、语法合乎规范。</td></tr><tr><td>0.5</td><td>意思基本明白，表达基本清楚，语音、语调基本正确，词语、语法有错误。</td></tr><tr><td>0</td><td>答非所问，或错误很多，不能达意。</td></tr></tbody></table><h4 id="其它版本">1.7.3.3. 其它版本</h4><ul><li>江苏中考（2档）<a href="https://jys.jsies.cn/htmledit/uploadfile/20190111153949047.pdf">^江苏中考</a>、深圳中考、衢州中考</li></ul><h4 id="维度分">1.7.3.4. 维度分</h4><p>驰声：内容、语法、发音、流利度</p><p>先声：完整度、发音、流利度，只建议展示总分</p><h2 id="故事复述">1.8. 故事复述</h2><p><a href="https://baike.baidu.com/item/%E5%B9%BF%E4%B8%9C%E9%AB%98%E8%80%83%E8%8B%B1%E8%AF%AD%E5%90%AC%E8%AF%B4%E8%80%83%E8%AF%95/2678957">^广东高考</a></p><h3 id="题型说明-1">1.8.1. 题型说明</h3><p>Retelling(故事复述)，要求考生先听一段大约两分钟的独白，录音播放两遍。考生准备一分钟之后开始复述所听的内容。要求考生尽可能使用自己的语言复述，而且复述内容应涵盖尽可能多的原文信息点。选取的独白其体裁主要以记述文和议论文为主。</p><h3 id="示例-1">1.8.2. 示例</h3><p><font style="background: yellow">（300词左右）</font></p><p><strong>A Young Man’s Present</strong></p><p>A young man who lived in London was in love with a beautiful girl. Soon she became his girlfriend. The man was very poor while the girl was rich. The young man wanted to give her a present on her birthday. He wanted to buy something beautiful for her, but he had no idea how to do it, as he had very little money. The next morning he went to a shop. There were many fine things: rings, gold watches, diamonds — but all these things were too expensive. There was one thing he could not take his eyes off. It was a beautiful vase. That was a suitable present for his girlfriend. He had been looking at the vase for half an hour when the manager of the shop noticed him. The young man looked so pale, sad and unhappy that the manager asked what had happened to him.</p><p>The young man told him everything, The manager felt sorry for him and decided to help him. He came up with a good idea. The manager pointed to the corner of the shop. To his great surprise the young man saw a vase broken into many pieces. The manager said: “I can help you. I shall order my worker to pack it and take it to your girlfriend. When he enters the room, he will drop it.”</p><p>On the birthday of his girlfriend the young man was very excited.</p><p>Everything happened as had been planned. The worker brought in the vase, and as he entered the room, he dropped it. There was horror on everybody’s face. When the vase was unpacked the guests saw that each piece was packed separately.</p><h3 id="评分标准-2">1.8.3. 评分标准</h3><table><thead><tr><th></th><th>内容</th><th>语言</th><th>流利</th><th>语音</th></tr></thead><tbody><tr><td>权重</td><td>50%</td><td>16.7%</td><td>20.8%</td><td>12.5%</td></tr><tr><td>考察点</td><td>原文信息点被覆盖的比例</td><td>语法</td><td></td><td>语音语调</td></tr></tbody></table><p>考生不按话题规定内容表述或套背内容毫不相干的范文：0分<a href="%5B%E5%B9%BF%E8%A5%BF%E9%AB%98%E8%80%83-2021%EF%BC%88%E6%8B%9B%E7%94%9F%E8%80%83%E8%AF%95%E9%99%A2%EF%BC%89%5D(https://www.gxeea.cn/gallary/upload_images/1173_26561_1606206201913.pdf)">^广西高考</a></p><h2 id="话题简述">1.9. 话题简述</h2><h2 id="信度、效度">1.10. 信度、效度</h2><ul><li>信度：多位专家打分，分数是否一致<ul><li>人工评分平均相关度、平均误差：计算评测员1与其它评测员的平均分的相关度、平均误差，作为评测员1的评分性能；以此类推；取多名评测员的平均作为人工评分性能</li></ul></li><li>效度：分数能否真实反映学生水平</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音评测 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>英文口语评测功能</title>
      <link href="/blog/yu-yin/yu-yin-ping-ce/ying-wen-kou-yu-ping-ce-gong-neng/"/>
      <url>/blog/yu-yin/yu-yin-ping-ce/ying-wen-kou-yu-ping-ce-gong-neng/</url>
      
        <content type="html"><![CDATA[<h1 id="英文口语评测功能">1. 英文口语评测功能</h1><h2 id="技术文档">1.1. 技术文档</h2><ul><li>科大讯飞：<a href="https://www.xfyun.cn/doc/Ise/IseAPI.html#%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E">https://www.xfyun.cn/doc/Ise/IseAPI.html#接口说明</a></li><li>驰声：<a href="https://www.chivox.com/opendoc/#/ChineseDoc/coreEn/">https://www.chivox.com/opendoc/#/ChineseDoc/coreEn/</a></li><li>先声：<a href="https://open.singsound.com/doc/engine?type=engine-en-en.word.score">https://open.singsound.com/doc/engine?type=engine-en-en.word.score</a></li></ul><h2 id="题型">1.2. 题型</h2><table><thead><tr><th>题型</th><th>科大讯飞</th><th>驰声</th><th>先声</th></tr></thead><tbody><tr><td>音标朗读</td><td></td><td>√ 自定义文本音标</td><td>√</td></tr><tr><td>单词朗读</td><td>√</td><td>√</td><td>√</td></tr><tr><td>单词纠音（音素识别）</td><td></td><td>√</td><td>√</td></tr><tr><td>句子朗读</td><td>√</td><td>√</td><td>√ 支持音频对比，返回音量、语调、语速相关度得分</td></tr><tr><td>句子纠音</td><td></td><td>√</td><td></td></tr><tr><td>篇章朗读</td><td>√</td><td>√</td><td>√</td></tr><tr><td>背诵</td><td></td><td>√ 篇章朗读题型背诵模式，要求严格按顺序朗读</td><td>√</td></tr><tr><td>句子选读</td><td></td><td></td><td>√ 返回实际朗读的是第几个句子</td></tr><tr><td>自然拼读</td><td></td><td></td><td>√ <font style="background: green">（文本形式不明确）</font></td></tr><tr><td>选择</td><td>√</td><td>√ 支持单选、多选</td><td>√ <br>支持扩展选择题：用户可以在事先设定的固定答案基础上扩展表述；引擎检测到读的更像哪个答案，就会有对应的得分。支持设置错误关键词。<br>支持设置解码网络：常规、精简（解码速度快，但效果下降；当参考文本较多时，可以设置）</td></tr><tr><td>问答</td><td>√</td><td>√</td><td>√ 支持设置错误关键词</td></tr><tr><td>复述、口头翻译、看图说话、口头作文</td><td>√</td><td>√</td><td>√</td></tr><tr><td>自由识别</td><td></td><td>√</td><td></td></tr></tbody></table><h2 id="功能配置">1.3. 功能配置</h2><table><thead><tr><th></th><th>科大讯飞</th><th>驰声</th><th>先声</th></tr></thead><tbody><tr><td>区分英美式发音</td><td></td><td>支持K12词汇</td><td>√</td></tr><tr><td>自定义音标</td><td>√ 支持指定数字的读法</td><td>√</td><td>√</td></tr><tr><td>集外词</td><td></td><td>√</td><td>√</td></tr><tr><td>人群定制</td><td>传入group（成人、中学、小学）、grade（年级，junior、middle、senior）</td><td>自适应少儿、成人群体</td><td>儿童单词、句子为单独的题型；看图说话、复述支持设置，影响打分松紧度</td></tr><tr><td>松紧调节</td><td>仅中文评测支持，3档</td><td>线性调节</td><td>朗读题 5档；问答题 0.8-1.5线性调节</td></tr><tr><td>实时评测</td><td></td><td>√</td><td>√</td></tr></tbody></table><h2 id="评测结果">1.4. 评测结果</h2><table><thead><tr><th></th><th></th><th>科大讯飞</th><th>驰声</th><th>先声</th></tr></thead><tbody><tr><td>音频级</td><td>总分</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>发音准确度分</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>流畅度分</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>标准度&#x2F;韵律分</td><td>√</td><td>意群（sense）、重读、升降调</td><td>√ 意群、重读、升降调占比分别为50%、25%、25%</td></tr><tr><td></td><td>完整度分</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>语法分</td><td></td><td>√</td><td></td></tr><tr><td></td><td>识别文本</td><td>自由表述题</td><td>句子纠音：若错读、增读的单词在参考文本内，正常识别，否则标记为unk。<br>自由识别：识别文本带标点符号，支持逗号、句号、问号、感叹号</td><td></td></tr><tr><td></td><td>关键词&#x2F;要点命中</td><td></td><td>√</td><td>√</td></tr><tr><td>句子级</td><td>句末升降调检错</td><td></td><td>√</td><td>√</td></tr><tr><td>词级</td><td>评分</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>正确、替换、漏读、增读、回读</td><td>√</td><td>√ 不区分回读</td><td>正确、漏读、回读</td></tr><tr><td></td><td>浊化</td><td></td><td>√</td><td></td></tr><tr><td></td><td>连读</td><td></td><td>√</td><td>√</td></tr><tr><td></td><td>失去爆破</td><td></td><td>√</td><td></td></tr><tr><td></td><td>重读</td><td></td><td>√</td><td>√</td></tr><tr><td></td><td>意群停顿</td><td></td><td>√</td><td>√</td></tr><tr><td></td><td>字母-音素对应</td><td></td><td>√</td><td>√</td></tr><tr><td>音节级</td><td>评分</td><td>√</td><td></td><td>√</td></tr><tr><td></td><td>发音检错</td><td>√</td><td></td><td></td></tr><tr><td></td><td>重音检错</td><td>√ 检测重读音节是否重读</td><td>√ 检测音节是否重读</td><td>√</td></tr><tr><td>音素级</td><td>评分</td><td></td><td>√</td><td>√</td></tr><tr><td></td><td>发音检错</td><td></td><td>√</td><td>√</td></tr><tr><td></td><td>发音诊断</td><td></td><td>√ 音素识别</td><td></td></tr><tr><td></td><td>正确、替换、漏读、增读、回读</td><td>√</td><td></td><td></td></tr></tbody></table><ul><li>音标、单词朗读仅发音准确度维度</li><li>标准度&#x2F;韵律分：科大讯飞：文本单词数&gt;&#x3D;5时才有</li><li>语法分：仅自由表述题有</li><li>驰声<ul><li>选择题、AITalk：返回置信度得分，可由应用层根据题目难易设置阈值（通常为75）判断结果是否正确</li></ul></li><li>先声<ul><li>句子朗读：统计各音素出现的次数、平均发音得分</li></ul></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音评测 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>小妇人</title>
      <link href="/blog/books/xiao-fu-ren/"/>
      <url>/blog/books/xiao-fu-ren/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 书籍 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>和平战士</title>
      <link href="/blog/videos/he-ping-zhan-shi/"/>
      <url>/blog/videos/he-ping-zhan-shi/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 视频 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>定风波</title>
      <link href="/blog/words/ding-feng-bo/"/>
      <url>/blog/words/ding-feng-bo/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 文字 </category>
          
          <category> 诗词 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch</title>
      <link href="/blog/ji-qi-xue-xi/kuang-jia/pytorch/"/>
      <url>/blog/ji-qi-xue-xi/kuang-jia/pytorch/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CTC</title>
      <link href="/blog/ji-qi-xue-xi/loss/ctc/"/>
      <url>/blog/ji-qi-xue-xi/loss/ctc/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> loss </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>音标</title>
      <link href="/blog/yu-yin/yu-yin-xue/yin-biao/"/>
      <url>/blog/yu-yin/yu-yin-xue/yin-biao/</url>
      
        <content type="html"><![CDATA[<h1 id="音标">1. 音标</h1><h2 id="符号表">1.1. 符号表</h2><h3 id="辅音">1.1.1. 辅音</h3><table><thead><tr><th>辅音</th><th>单词</th><th>音标</th></tr></thead><tbody><tr><td>p</td><td>pen</td><td>&#x2F;pen&#x2F;</td></tr><tr><td>b</td><td>bad</td><td>&#x2F;bæd&#x2F;</td></tr><tr><td>t</td><td>tea</td><td>&#x2F;tiː&#x2F;</td></tr><tr><td>d</td><td>did</td><td>&#x2F;dɪd&#x2F;</td></tr><tr><td>k</td><td>cat</td><td>&#x2F;kæt&#x2F;</td></tr><tr><td>ɡ</td><td>get</td><td>&#x2F;ɡet&#x2F;</td></tr><tr><td>tʃ</td><td>chain</td><td>&#x2F;tʃeɪn&#x2F;</td></tr><tr><td>dʒ</td><td>jam</td><td>&#x2F;dʒæm&#x2F;</td></tr><tr><td>f</td><td>fall</td><td>&#x2F;fɔːl&#x2F;</td></tr><tr><td>v</td><td>van</td><td>&#x2F;væn&#x2F;</td></tr><tr><td>θ</td><td>thin</td><td>&#x2F;θɪn&#x2F;</td></tr><tr><td>ð</td><td>this</td><td>&#x2F;ðɪs&#x2F;</td></tr><tr><td>s</td><td>see</td><td>&#x2F;siː&#x2F;</td></tr><tr><td>z</td><td>zoo</td><td>&#x2F;zuː&#x2F;</td></tr><tr><td>ʃ</td><td>shoe</td><td>&#x2F;ʃuː&#x2F;</td></tr><tr><td>ʒ</td><td>vision</td><td>&#x2F;ˈvɪʒn&#x2F;</td></tr><tr><td>h</td><td>hat</td><td>&#x2F;hæt&#x2F;</td></tr><tr><td>m</td><td>man</td><td>&#x2F;mæn&#x2F;</td></tr><tr><td>n</td><td>now</td><td>&#x2F;naʊ&#x2F;</td></tr><tr><td>ŋ</td><td>sing</td><td>&#x2F;sɪŋ&#x2F;</td></tr><tr><td>l</td><td>leg</td><td>&#x2F;leɡ&#x2F;</td></tr><tr><td>r</td><td>red</td><td>&#x2F;red&#x2F;</td></tr><tr><td>j</td><td>yes</td><td>&#x2F;jes&#x2F;</td></tr><tr><td>w</td><td>wet</td><td>&#x2F;wet&#x2F;</td></tr></tbody></table><h3 id="元音">1.1.2. 元音</h3><table><thead><tr><th>牛津</th><th>单词</th><th>音标</th><th>备注</th><th>朗文</th><th>-</th><th>-</th><th>-</th><th>cambridge</th><th>-</th><th>-</th><th>-</th><th>-</th></tr></thead><tbody><tr><td>ʌ</td><td>cup</td><td>&#x2F;kʌp&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɑː</td><td>father</td><td>&#x2F;ˈfɑːðə(r)&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɒ</td><td>got</td><td>&#x2F;ɡɒt&#x2F;</td><td>British English</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɔː</td><td>saw</td><td>&#x2F;sɔː&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ə</td><td>about</td><td>&#x2F;əˈbaʊt&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɜː</td><td>fur</td><td>&#x2F;fɜː(r)&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɪ</td><td>sit</td><td>&#x2F;sɪt&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>i</td><td>happy</td><td>&#x2F;ˈhæpi&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>iː</td><td>see</td><td>&#x2F;siː&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ʊ</td><td>put</td><td>&#x2F;pʊt&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>u</td><td>actual</td><td>&#x2F;ˈæktʃuəl&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>uː</td><td>too</td><td>&#x2F;tuː&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>e</td><td>bed</td><td>&#x2F;bed&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>æ</td><td>cat</td><td>&#x2F;kæt&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>aɪ</td><td>my</td><td>&#x2F;maɪ&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>eɪ</td><td>say</td><td>&#x2F;seɪ&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɔɪ</td><td>boy</td><td>&#x2F;bɔɪ&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>aʊ</td><td>now</td><td>&#x2F;naʊ&#x2F;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>əʊ</td><td>go</td><td>&#x2F;ɡəʊ&#x2F;</td><td></td><td>British English</td><td>oʊ</td><td>note</td><td>American English</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ɪə</td><td>near</td><td>&#x2F;nɪə(r)&#x2F;</td><td>British English</td><td><del>British English</del></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>eə</td><td>hair</td><td>&#x2F;heə(r)&#x2F;</td><td>British English</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>ʊə</td><td>pure</td><td>&#x2F;pjʊə(r)&#x2F;</td><td>British English</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>ɒː</td><td>dog</td><td>American English</td><td>ɚ</td><td>mother</td><td></td><td>American English，轻音节</td><td>ər</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>iə</td><td>peculiar</td><td></td><td>ɝ</td><td>worm</td><td></td><td>American English，重读音节</td><td>ər</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>t̬</td><td>butter</td><td>&#x2F;ˈbʌt̬.ɚ&#x2F;</td><td>American English</td><td>[ɾ]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>l̩</td><td>little</td><td>&#x2F;ˈlɪt.l̩&#x2F;</td><td></td><td>[ɫ]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td><sup>ə</sup>l,<sup>ə</sup>m,<sup>ə</sup>n</td><td></td><td>&#x2F;leɪb.<sup>ə</sup>l&#x2F;</td><td></td><td>(ə)l …</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td><sup>r</sup></td><td>four apples</td><td>fɔː<sup>r</sup> + ˈæp.l ̩z &#x3D; fɔːˈræp.l ̩z</td><td>British English，在元音前时才发音</td><td>(r)</td></tr></tbody></table><h3 id="备注">1.1.3. 备注</h3><ul><li>&#x2F;i&#x2F;可以发成&#x2F;iː&#x2F;或&#x2F;ɪ&#x2F;或两者之间折中的音；&#x2F;u&#x2F;代表&#x2F;uː&#x2F;和&#x2F;ʊ&#x2F;之间的弱元音</li><li>&#x2F;ɒ&#x2F;只出现在英式英语中，美式英语的发音通常是&#x2F;ɔː&#x2F;或&#x2F;ɑː&#x2F;</li><li>(r)：只有紧跟的是下一个单词开头的元音时，英式发音才会出现&#x2F;r&#x2F;，如far away；否则省略&#x2F;r&#x2F;。对于美式英语来说，所有的&#x2F;r&#x2F;都应该发音。</li><li>&#x2F;l̩&#x2F; 、&#x2F;n̩&#x2F;、(&#x2F;m̩)&#x2F;：成音节，如final &#x2F;ˈfaɪnl&#x2F;，发音为[<sup>ə</sup>l] or [<sup>ə</sup>n] </li><li>音位变体<ul><li><p>&#x2F;t&#x2F;音素还包含闪音[ɾ]和glottal stop [ʔ]。 </p><p>[ɾ] 发音像快速的&#x2F;d&#x2F;，美式发音，在很多拼写为-t-或-tt-的单词中，在元音或&#x2F;r&#x2F;之后、非重读元音或音节&#x2F;l&#x2F;之前，如city &#x2F;ˈsɪt̮ɪ &#x2F;; parting &#x2F;ˈpɑrt̮ɪŋ &#x2F;; little &#x2F;ˈlɪt̮l &#x2F;； </p><p>英美式发音有时会用glottal stop [ʔ] (声带短暂的闭合)来表达&#x2F;t&#x2F;，比如football &#x2F;ˈfʊtbɔːl&#x2F;和button &#x2F;ˈbʌtn&#x2F;。</p></li><li><p>&#x2F;l&#x2F;在元音之前或中间时（如 like）与在其他位置时（如 full [ɫ] ）发音不同</p></li><li><p>&#x2F;r&#x2F; [ɹ]如red</p></li></ul></li><li>&#x2F;x&#x2F;：摩擦音，如苏格兰的loch、爱尔兰的lough &#x2F;lɒx&#x2F;</li><li>˜：鼻元音，可能在某些源自法语的单词中保留，如penchant &#x2F;ˈpɒ̃ʃɒ̃&#x2F;</li><li>有的发音标注了强、弱形式，给出的第一个发音通常代表最常用的；但是当一个单词被强调时，应该采用strong form；当单词位于句子末尾时，也通常使用strong form。如can &#x2F;kən&#x2F;, strong form &#x2F;kæn&#x2F;</li><li>重读音节相对loud、持续时间长、发音清晰，并且可以通过音调被注意到。重读音节通常不包含弱元音&#x2F;ə&#x2F;、&#x2F;i&#x2F;或&#x2F;u&#x2F;。 </li><li>英语音素 48 vs 44<blockquote><p>传统语音学认为：英语有48个音素。一个音素对应一个音标，所以共有48个国际音标。这也是我们国内更加熟知的一种音标体系。</p><p>现代语音学认为：英语有44个音素。因为现代语音学认为 &#x2F;tr&#x2F; &#x2F;dr&#x2F; &#x2F;ts&#x2F; &#x2F;dz&#x2F; 这四个不是独立的音素，而是辅音连缀。</p><p><a href="https://zhuanlan.zhihu.com/p/31484071">https://zhuanlan.zhihu.com/p/31484071</a></p></blockquote><blockquote><p>&#x2F;ts&#x2F;、&#x2F;dz&#x2F;、&#x2F;tr&#x2F;、&#x2F;dr&#x2F; 如果作为辅音连缀简单地连读，影响正确发音</p><p><a href="https://www.hjenglish.com/yinbiao/p776611/">https://www.hjenglish.com/yinbiao/p776611/</a></p></blockquote></li></ul><h3 id="参考">1.1.4. 参考</h3><ul><li><a href="https://www.oxfordlearnersdictionaries.com/about/english/pronunciation_english">https://www.oxfordlearnersdictionaries.com/about/english/pronunciation_english</a></li><li><a href="https://www.oxfordlearnersdictionaries.com/about/pronunciation/_american_english">https://www.oxfordlearnersdictionaries.com/about/pronunciation\_american_english</a></li><li><a href="https://www.ldoceonline.com/howtouse.html">https://www.ldoceonline.com/howtouse.html</a></li><li><a href="https://dictionary.cambridge.org/help/phonetics.html">https://dictionary.cambridge.org/help/phonetics.html</a></li><li><a href="https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/%E8%8B%B1%E8%AA%9E%E5%9C%8B%E9%9A%9B%E9%9F%B3%E6%A8%99">https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/英語國際音標</a></li><li><a href="https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/DJ%E9%9F%B3%E6%A8%99">https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/DJ音標</a></li><li><a href="https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/KK%E9%9F%B3%E6%A8%99">https://go-xyz.xyz/extdomains/zh.wikipedia.org/wiki/KK音標</a></li><li>音素、音标、国际音标（IPA）、DJ音标、KK音标、宽式标音等 <a href="https://en-yinbiao.xiao84.com/study">https://en-yinbiao.xiao84.com/study</a></li><li>音标特殊字符unicode编码：<a href="http://www.fmddlmyy.cn/text65.html">http://www.fmddlmyy.cn/text65.html</a> （注意ɡ、ː、ˈ、ˌ）</li></ul><h2 id="词典">1.2. 词典</h2><ul><li><p>主流英语词典：朗文、牛津、剑桥、柯林斯、韦式 <a href="https://www.jianshu.com/p/26d12a32f048">https://www.jianshu.com/p/26d12a32f048</a></p></li><li><p>朗文交际9000词 <a href="https://github.com/MuhammadYaseenKhan/Longman-Communication">https://github.com/MuhammadYaseenKhan/Longman-Communication</a></p></li><li><p>韦式词典</p><p><a href="https://www.merriam-webster.com/assets/mw/static/pdf/help/guide-to-pronunciation.pdf">https://www.merriam-webster.com/assets/mw/static/pdf/help/guide-to-pronunciation.pdf</a></p><p><a href="https://mdx.mdict.org/%E5%85%AD%E5%A4%A7%E7%9F%A5%E5%90%8D%E8%AF%8D%E5%85%B8/%E9%9F%A6%E6%B0%8F_Merriam-Webster/Merriam-Webster/Merriam-Webster/">https://mdx.mdict.org/六大知名词典/韦氏_Merriam-Webster/Merriam-Webster/Merriam-Webster/</a></p></li><li><p>数据堂英语发音词典：<a href="https://m.datatang.com/news/info/aboutus/451">https://m.datatang.com/news/info/aboutus/451</a></p></li></ul><h2 id="ARPAbet音素集">1.3. ARPAbet音素集</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEB3fda55097eb7eb054863211dc53ea73d?method=download&shareKey=fecd6d9867afa9c0ab9874d271e9ce46" alt="wiki"></p><p>元音区分是否重读，重音标记：0表示非重音，1表示主重音，2表示次重音</p><h3 id="arpabet-to-ipa">1.3.1. arpabet-to-ipa</h3><p><a href="https://github.com/wwesantos/arpabet-to-ipa/blob/master/src/App.php">https://github.com/wwesantos/arpabet-to-ipa/blob/master/src/App.php</a></p><h3 id="与48个音素的区别">1.3.2. 与48个音素的区别</h3><ul><li>无短元音&#x2F;ɒ&#x2F;，美式发音中多为&#x2F;ɑː&#x2F;或&#x2F;ɔː&#x2F;，如lot、long</li><li>无双元音&#x2F;ɪə&#x2F;、&#x2F;eə&#x2F;、&#x2F;ʊə&#x2F;，用两个单元音表示</li><li>无4个辅音连缀，用两个音标表示</li><li>&#x2F;ʌ&#x2F;、&#x2F;ə&#x2F;共用符号AH，美式英语中常为多发音，如but</li></ul><h3 id="CMU-Carnegie-Mellon-University-词典">1.3.3. CMU(Carnegie Mellon University)词典</h3><p><a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict/">http://www.speech.cs.cmu.edu/cgi-bin/cmudict/</a></p><p>CMU词典用于北美英语，采用ARPAbet音素集，元音区分是否重读</p><p>39个音素：</p><p>元音(15)：AA, AE, AH, AO, AW, AY, EH, ER, EY, IH, IY, OW, OY, UH, UW</p><p>辅音(24)：B, CH, D, DH, F, G, HH, JH, K, L, M, N, NG, P, R, S, SH, T, TH, V, W, Y, Z, ZH</p><h2 id="发音学习视频">1.4. 发音学习视频</h2><ul><li>《BBC音标教程》Alex <a href="https://www.bilibili.com/video/BV127411n7nj">https://www.bilibili.com/video/BV127411n7nj</a></li><li>《英语语音》屠蓓 <a href="https://www.bilibili.com/video/BV1EP4y1p7p3">https://www.bilibili.com/video/BV1EP4y1p7p3</a></li><li>《美语从头学：美语音标》赖世雄  <a href="https://www.bilibili.com/video/BV1qo4y1S7tY/">https://www.bilibili.com/video/BV1qo4y1S7tY/</a></li><li>英语兔 <a href="https://space.bilibili.com/483162496/channel/series">https://space.bilibili.com/483162496/channel/series</a></li></ul><h2 id="频谱">1.5. 频谱</h2><p><a href="https://home.cc.umanitoba.ca/~krussll/phonetics/acoustic/spectrogram-sounds.html">https://home.cc.umanitoba.ca/~krussll/phonetics/acoustic/spectrogram-sounds.html</a></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音学 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>GOP</title>
      <link href="/blog/yu-yin/yu-yin-ping-ce/gop/"/>
      <url>/blog/yu-yin/yu-yin-ping-ce/gop/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音评测 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>序列区分性训练</title>
      <link href="/blog/yu-yin/yu-yin-shi-bie/xu-lie-qu-fen-xing-xun-lian/"/>
      <url>/blog/yu-yin/yu-yin-shi-bie/xu-lie-qu-fen-xing-xun-lian/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音识别 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>解码器</title>
      <link href="/blog/yu-yin/yu-yin-shi-bie/jie-ma-qi/"/>
      <url>/blog/yu-yin/yu-yin-shi-bie/jie-ma-qi/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音识别 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>语言模型</title>
      <link href="/blog/yu-yin/yu-yin-shi-bie/yu-yan-mo-xing/"/>
      <url>/blog/yu-yin/yu-yin-shi-bie/yu-yan-mo-xing/</url>
      
        <content type="html"><![CDATA[<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
      
      
      <categories>
          
          <category> 语音 </category>
          
          <category> 语音识别 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
